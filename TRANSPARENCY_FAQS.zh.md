# AutoGen：负责任的 AI 常见问题解答

## 什么是 AutoGen？
AutoGen 是一个用于简化大型模型（LLM）工作流编排、优化和自动化的框架。它提供可定制且可对话的 agent，能利用最先进 LLM（如 GPT-4）的强大能力，同时通过集成人类与工具并在多个 agent 间进行对话来缓解其局限性。

## AutoGen 能做什么？
AutoGen 是一个实验性框架，用于构建复杂的多 agent 会话系统，支持：
- 定义具有专门能力和角色的一组 agent。
- 定义 agent 之间的交互行为，例如 agent 在收到其他 agent 的消息后如何回复。

基于以会话为中心的设计，AutoGen 的优势包括：
- 自然处理歧义、反馈、进展与协作。
- 支持带工具的编码相关任务，通过来回交互进行故障排查。
- 允许用户通过对话中的 agent 选择加入或退出。
- 多个专家型 agent 协作以实现集合目标。

## AutoGen 的预期用途是什么？
请注意，AutoGen 是正在积极开发的开源库，主要用于研究目的。在将其用于下游应用前，应进行额外的鲁棒性与安全评估以降低潜在伤害或偏见。

AutoGen 是通用基础设施，可用于多种场景，例如：
- 构建能解决更复杂任务的 LLM 工作流：通过让多个 agent 对话来分解复杂问题或提供不同视角。
- 应用特定的 agent 拓扑：用户可为不同域定义不同的 agent 交互拓扑。
- 代码生成与执行：可实现负责写代码的 agent 与负责执行代码的 agent，并在执行前让用户确认。
- 问答系统：使用检索增强生成的 agent 来回答问题。
- 多 agent 聊天与辩论：让用户与多个 agent 同时交互。

尽管 AutoGen 提供自动化，依然建议在关键决策环节保持人工参与，避免自动将 LLM 生成内容发布到真实环境中。

## AutoGen 如何评估？使用了哪些指标？
- 我们对项目进行了负责 AI 的安全测试，例如针对跨域提示注入（prompt injection）的测试，结果符合预期，没有出现越狱迹象。
- AutoGen 在六个示例应用上进行了评估，以展示其在简化多 agent 应用开发方面的潜力。评估指标包括任务成功率和在某些场景下的实现效率（例如减少开发工作量）。更多细节见：https://aka.ms/autogen-pdf。
- 我们在 GAIA 基准上评估了一个 AutoGen agent 团队，并取得截至 2024-03-01 的领先结果（SOTA）。

## AutoGen 的局限性是什么？如何将影响降到最低？
AutoGen 依赖于现有 LLM，因此保有大型语言模型的常见局限性，例如：
- 数据偏差：训练数据中的偏见可能导致模型输出有偏见或不公平。
- 缺乏真实世界语境理解：模型可能生成不准确或不切实际的回答。
- 缺乏透明性：模型行为可能像“黑箱”，难以解释输出原因。
- 内容危害：模型可能生成有害内容，应结合内容审核服务与安全提示策略。
- 虚构或无依据的内容：不要在关键决策中完全依赖模型，需以权威数据源为准。
- 潜在滥用：在缺乏保护措施下，模型可能被用于生成虚假信息或有害内容。

此外，多 agent 框架可能带来额外风险：
- 隐私与数据保护：需确保会话与用户数据的保护，并根据需求采取适当措施。
- 问责与透明：多 agent 协作时，需建立清晰的问责机制与可追溯流程。
- 信任与依赖：需向用户明确说明系统能力与局限，避免盲目信任。
- 安全与非预期后果：允许 agent 执行代码或调用外部功能等能力会引入风险，应保持人类在环并限制可执行操作。

## 有哪些运营性设置有助于负责任地使用 AutoGen？
- 代码执行：建议使用容器（例如 Docker）来隔离执行环境；优先使用受限的函数调用而非任意代码执行。
- 人类参与：鼓励监督者在需要时介入以引导 agent，示例中均要求用户在执行代码前确认。
- agent 模块化：可通过为不同 agent 赋予不同权限来实现检查与制衡，例如添加专职守护 agent。
- LLM 的选择：可根据责任性选择合适的 LLM，例如默认示例使用 GPT-4o，开发者应参考模型提供方的使用政策并在必要时添加内容审核或安全提示。